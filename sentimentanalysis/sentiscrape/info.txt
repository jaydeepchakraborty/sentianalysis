12 th July
Imagine there are 100 positive cases among 10,000 cases.
You want to predict which ones are positive
you pick 200 to have a better chance of catching many of the 100 positive cases

TN / True Negative: case was negative and predicted negative
TP / True Positive: case was positive and predicted positive
FN / False Negative: case was positive but predicted negative
FP / False Positive: case was negative but predicted positive

you count how many of the 10,000 cases fall in each bucket

TN: 9,760
TP: 60
FN: 40
FP: 140

What percent of your predictions were correct?
the "accuracy" was (9,760+60) out of 10,000 = 98.2%


What percent of the positive cases did you catch?
the "recall" was 60 out of 100 = 60%
What percent of positive predictions were correct? 
the "precision" was 60 out of 200 = 30%


70% for the training set and 30% for the test
----------------------------------------------------------------------------------
14 th July
Problem statements:
1) feature extraction algorithm
2) how nltk.classify.apply_features is working and what is the output

----------------------------------------------------------------------------------
15 th July
traindata in init, possible ways to improve:
1) do online survey, get feedback on the output //feedback
2) use published dictionary, like 
http://sentic.net/downloads/
http://sentiwordnet.isti.cnr.it/
3) how you are doing feature extraction.(algo - frequency,)
4) postive and negative score
5) not only positive, negative add more options like neutral and not_understand
----------------------------------------------------------------------------------
17th July
1) do online survey, get feedback on the output //feedback
2) use published dictionary, like 
http://sentic.net/downloads/
http://sentiwordnet.isti.cnr.it/
3) validation of current accuracy, precision, recall, and f-measure

https://www.kaggle.com/katarz/d/kaggle/hillary-clinton-emails/sentiment/run/211290